<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Ai-Ml on Kyungwook&#39;s Devlog</title>
    <link>https://kwbaek.github.io/categories/ai-ml/</link>
    <description>Recent content in Ai-Ml on Kyungwook&#39;s Devlog</description>
    <generator>Hugo -- 0.155.3</generator>
    <language>ko-kr</language>
    <lastBuildDate>Sun, 01 Mar 2026 21:00:00 +0900</lastBuildDate>
    <atom:link href="https://kwbaek.github.io/categories/ai-ml/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI/ML 트렌드: 이제는 ‘정답률’보다 ‘운영 가능성’이 경쟁력이다</title>
      <link>https://kwbaek.github.io/posts/2026-03-01-ai-agent-operations-over-benchmarks/</link>
      <pubDate>Sun, 01 Mar 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-03-01-ai-agent-operations-over-benchmarks/</guid>
      <description>&lt;p&gt;오늘 Discord &lt;code&gt;#ai-ml-trends&lt;/code&gt; 채널에서 가장 흥미로웠던 흐름은 한 문장으로 요약됩니다. &lt;strong&gt;모델이 똑똑한지보다, 실제로 믿고 운영할 수 있는지가 더 중요한 평가축으로 올라오고 있다&lt;/strong&gt;는 점입니다.&lt;/p&gt;
&lt;p&gt;최근 몇 년은 벤치마크 점수 경쟁이 AI 발전의 중심이었습니다. 그런데 오늘 올라온 연구들을 보면 초점이 조금 달라졌습니다. 모델이 높은 점수를 내는지보다, 사람이 통제하고 해석하고 재현할 수 있는 방향으로 관심이 이동하고 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;오늘의-핵심-신호-3가지&#34;&gt;오늘의 핵심 신호 3가지&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Knob: Physics-Inspired Gating Interface&lt;/strong&gt;&lt;br&gt;
단순히 성능을 올리는 게 아니라, 모델 내부 동역학을 사람이 이해 가능한 “노브” 형태로 조절하려는 시도입니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>학습보다 추론이 전장: Nvidia 새 칩 소식이 보여준 AI 인프라의 무게중심 이동</title>
      <link>https://kwbaek.github.io/posts/2026-02-28-inference-is-the-new-ai-bottleneck/</link>
      <pubDate>Sat, 28 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-28-inference-is-the-new-ai-bottleneck/</guid>
      <description>&lt;p&gt;오늘 Discord &lt;code&gt;#ai-ml-trends&lt;/code&gt; 채널에서 가장 중요한 신호는 Reuters가 보도한 &lt;strong&gt;Nvidia의 신규 추론(inference) 가속 시스템 준비&lt;/strong&gt; 뉴스였습니다. 겉으로는 또 하나의 칩 출시 소식처럼 보이지만, 실제로는 AI 산업의 중심축이 어디로 이동하고 있는지를 보여주는 상징적인 사건이라고 봅니다.&lt;/p&gt;
&lt;p&gt;지난 2년은 “누가 더 큰 모델을 더 빨리 학습시키는가”가 핵심 경쟁이었습니다. 그래서 시장의 관심도 자연스럽게 학습용 GPU 수급, 대형 클러스터, CAPEX 규모에 쏠려 있었습니다. 그런데 지금은 상황이 달라졌습니다. 생성형 AI가 대중 서비스와 기업 워크플로우에 본격 탑재되면서, 비용과 성능의 병목이 학습보다 &lt;strong&gt;추론 단계&lt;/strong&gt;에서 더 크게 드러나고 있습니다. 사용자가 실제로 체감하는 것은 학습 성과가 아니라 응답 지연(latency), 처리량(throughput), 그리고 토큰당 비용이기 때문입니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>범용 AI보다 강한 도메인 AI: 교육 현장에서 드러난 성과 격차</title>
      <link>https://kwbaek.github.io/posts/2026-02-27-domain-ai-beats-general-ai-in-education/</link>
      <pubDate>Fri, 27 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-27-domain-ai-beats-general-ai-in-education/</guid>
      <description>&lt;p&gt;오늘 Discord &lt;code&gt;#ai-ml-trends&lt;/code&gt;에서 가장 눈에 띈 뉴스는 Reuters가 보도한 &lt;strong&gt;Pearson의 실적 코멘트&lt;/strong&gt;였습니다. 요지는 명확합니다. &lt;em&gt;자사 커리큘럼에 맞춰 설계된 AI 코스웨어는 성적 개선 효과를 보였지만, 범용 AI를 단독 사용한 경우 학습·추론 능력에 부정적 영향이 관찰됐다&lt;/em&gt;는 것입니다.&lt;/p&gt;
&lt;p&gt;이 포인트가 중요한 이유는 단순히 “어떤 모델이 더 똑똑하냐”의 문제가 아니기 때문입니다. 교육은 정답 생성보다 &lt;strong&gt;학습 경로 설계, 오개념 교정, 피드백 타이밍, 평가 정합성&lt;/strong&gt;이 더 중요합니다. 범용 챗봇은 질문에 답은 잘하지만, 학습자 수준·수업 목표·평가 루브릭과 엮인 ‘수업 문맥’을 기본적으로 알지 못합니다. 반면 도메인 AI는 학습 데이터와 인터랙션 자체가 특정 교육 목적에 맞춰져 있어, 학습 효과를 일관되게 밀어 올릴 가능성이 큽니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>반응형에서 선제형으로: ProactiveMobile이 여는 모바일 AI 에이전트의 다음 경쟁축</title>
      <link>https://kwbaek.github.io/posts/2026-02-26-ai-proactive-mobile-agents/</link>
      <pubDate>Thu, 26 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-26-ai-proactive-mobile-agents/</guid>
      <description>&lt;p&gt;오늘 AI/ML 트렌드 채널에서 가장 흥미로웠던 포인트는 &lt;strong&gt;모바일 AI 에이전트의 평가 기준이 ‘반응형(reactive)’에서 ‘선제형(proactive)’으로 이동&lt;/strong&gt;하고 있다는 점입니다. 특히 &lt;code&gt;ProactiveMobile&lt;/code&gt; 벤치마크는 “사용자가 명령하면 수행하는 모델”을 넘어, 사용 맥락을 이해하고 먼저 제안/행동하는 모델을 별도의 축으로 측정한다는 점에서 의미가 큽니다.&lt;/p&gt;
&lt;h2 id=&#34;왜-이-흐름이-중요한가&#34;&gt;왜 이 흐름이 중요한가&lt;/h2&gt;
&lt;p&gt;지금까지 모바일 에이전트의 성능 비교는 대체로 다음 질문에 머물렀습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;명령을 정확히 이해하는가?&lt;/li&gt;
&lt;li&gt;여러 앱 단계를 실수 없이 수행하는가?&lt;/li&gt;
&lt;li&gt;응답 지연은 충분히 짧은가?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;하지만 실제 사용자 경험에서 중요한 순간은 종종 &lt;strong&gt;명령 이전&lt;/strong&gt;에 발생합니다. 예를 들어 출근 시간 교통 지연, 정기 결제 만료, 회의 직전 자료 준비 같은 상황은 “요청 후 실행”보다 “상황 인지 후 제안”이 훨씬 큰 가치를 만듭니다. 결국 모바일 AI의 승부처는 단순 자동화가 아니라, &lt;strong&gt;맥락 추론 + 타이밍 + 과잉개입 제어&lt;/strong&gt;의 균형으로 넘어가고 있습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI 인프라의 진짜 병목: 모델이 아니라 전력과 정책</title>
      <link>https://kwbaek.github.io/posts/2026-02-25-ai-infrastructure-power-shift/</link>
      <pubDate>Wed, 25 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-25-ai-infrastructure-power-shift/</guid>
      <description>&lt;p&gt;오늘 Discord &lt;code&gt;#ai-ml-trends&lt;/code&gt; 채널을 보면, 가장 큰 흐름은 논문 하나의 성능 경쟁이 아니라 &lt;strong&gt;AI 인프라의 병목이 계산 자원에서 전력·정책·공급망으로 이동하고 있다는 점&lt;/strong&gt;입니다.&lt;/p&gt;
&lt;p&gt;특히 인상적이었던 신호는 세 가지입니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;미국에서 빅테크에 데이터센터 전력을 자체 조달하라는 압박이 공개적으로 등장했다는 점&lt;/li&gt;
&lt;li&gt;유럽 클린에너지 관련 종목이 AI 전력 수요 기대와 정책 리스크 사이에서 큰 변동성을 보인다는 점&lt;/li&gt;
&lt;li&gt;Alcoa 같은 전통 산업 자산이 데이터센터 부지/전력 인프라 관점에서 재평가되고 있다는 점&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이 세 가지를 합치면 메시지는 명확합니다. 이제 AI 경쟁은 “누가 더 좋은 모델을 만들었는가”에 더해, &lt;strong&gt;누가 더 안정적으로 전력·부지·규제 조건을 확보했는가&lt;/strong&gt;의 싸움이 됐습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI 경쟁의 중심축 이동: 모델 성능에서 운영 거버넌스로</title>
      <link>https://kwbaek.github.io/posts/2026-02-24-ai-governance-shift-frontier/</link>
      <pubDate>Tue, 24 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-24-ai-governance-shift-frontier/</guid>
      <description>&lt;p&gt;2026년 2월 24일 기준, 오늘 AI/ML 트렌드 채널에서 가장 중요한 신호는 &lt;strong&gt;&amp;ldquo;누가 더 똑똑한 모델을 만드느냐&amp;quot;보다 &amp;ldquo;누가 더 안전하고 운영 가능한 AI 시스템을 구축하느냐&amp;quot;로 경쟁의 기준이 바뀌고 있다는 점&lt;/strong&gt;입니다.&lt;/p&gt;
&lt;p&gt;가장 대표적인 사례가 OpenAI의 &lt;em&gt;Frontier&lt;/em&gt; 발표입니다. 이 발표는 단순히 모델 API를 늘리는 업데이트가 아니라, 에이전트를 실제 조직 내에서 배포하고 관리하기 위한 플랫폼 레이어(권한, 온보딩, 공유 컨텍스트, 거버넌스)를 전면에 내세웠다는 점에서 의미가 큽니다. 즉, 모델 자체의 성능 우위만으로는 더 이상 엔터프라이즈 시장을 장악하기 어렵고, 운영 체계 전체를 제공하는 쪽이 유리해지는 국면입니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI 모델 전쟁의 새로운 국면: Gemini 3.1 Pro부터 Claude Sonnet 4.6까지</title>
      <link>https://kwbaek.github.io/posts/2026-02-23-ai-model-wars-heat-up/</link>
      <pubDate>Mon, 23 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-23-ai-model-wars-heat-up/</guid>
      <description>&lt;p&gt;2026년 2월 셋째 주, AI 업계는 그야말로 &amp;lsquo;모델 대폭발&amp;rsquo; 시즌에 돌입했습니다. 주요 AI 기업들이 경쟁적으로 차세대 모델을 발표하며, 성능과 효율성의 경계를 다시 쓰고 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;google의-추론-강화-gemini-31-pro&#34;&gt;Google의 추론 강화: Gemini 3.1 Pro&lt;/h2&gt;
&lt;p&gt;Google DeepMind가 &lt;strong&gt;Gemini 3.1 Pro&lt;/strong&gt;를 발표했습니다. 이 모델은 복잡한 문제해결에 특화되었으며, ARC-AGI-2 벤치마크에서 **검증 점수 77.1%**를 기록했습니다. 단순한 질의응답을 넘어서, 멀티스텝 추론과 복잡한 작업 계획이 필요한 시나리오에서 강점을 보입니다.&lt;/p&gt;
&lt;p&gt;Gemini API, Vertex AI, Gemini 앱, NotebookLM을 통해 순차 롤아웃 중이며, 개발자부터 일반 사용자까지 폭넓게 영향을 미칠 것으로 예상됩니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI 에이전트의 위험한 과신: 실제로는 22% 성공하지만 77% 성공할 거라 예측</title>
      <link>https://kwbaek.github.io/posts/2026-02-22-ai-agent-overconfidence/</link>
      <pubDate>Sun, 22 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-22-ai-agent-overconfidence/</guid>
      <description>&lt;h2 id=&#34;ai-에이전트-자신의-능력을-과대평가하다&#34;&gt;AI 에이전트, 자신의 능력을 과대평가하다&lt;/h2&gt;
&lt;p&gt;최신 AI 에이전트 연구에서 충격적인 결과가 나왔습니다. AI 에이전트들이 작업 성공 확률을 예측할 때 실제 성능보다 훨씬 높게 평가하는 &lt;strong&gt;체계적인 과신(overconfidence)&lt;/strong&gt; 패턴을 보인다는 것입니다.&lt;/p&gt;
&lt;p&gt;arXiv에 공개된 &lt;a href=&#34;https://arxiv.org/abs/2602.06948&#34;&gt;&amp;ldquo;Agentic Uncertainty Reveals Agentic Overconfidence&amp;rdquo;&lt;/a&gt; 논문에 따르면, 일부 에이전트는 실제로 22%의 작업만 성공했음에도 불구하고 &lt;strong&gt;77%의 성공률을 예측&lt;/strong&gt;했습니다. 이는 3배 이상의 과대평가입니다.&lt;/p&gt;
&lt;h3 id=&#34;왜-이-문제가-중요한가&#34;&gt;왜 이 문제가 중요한가?&lt;/h3&gt;
&lt;p&gt;AI 에이전트가 실제 업무 환경에 배치되는 상황을 생각해보세요:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;의료 진단 에이전트&lt;/strong&gt;가 자신의 진단 정확도를 과대평가한다면?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;금융 거래 에이전트&lt;/strong&gt;가 리스크를 과소평가한다면?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;자율주행 에이전트&lt;/strong&gt;가 자신의 판단 능력을 과신한다면?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이런 과신은 단순한 정확도 문제를 넘어 &lt;strong&gt;신뢰와 안전의 문제&lt;/strong&gt;로 직결됩니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI 에이전트 시대의 서막: Claude Sonnet 4.6과 NIST 표준화 이니셔티브</title>
      <link>https://kwbaek.github.io/posts/2026-02-21-ai-agent-era-claude-sonnet-nist-standards/</link>
      <pubDate>Sat, 21 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-21-ai-agent-era-claude-sonnet-nist-standards/</guid>
      <description>&lt;h2 id=&#34;ai-에이전트-시대가-본격화되고-있다&#34;&gt;AI 에이전트 시대가 본격화되고 있다&lt;/h2&gt;
&lt;p&gt;2026년 2월, AI 업계에서 두 가지 중요한 발표가 있었습니다. Anthropic의 &lt;strong&gt;Claude Sonnet 4.6&lt;/strong&gt; 출시와 미국 NIST(국립표준기술연구소)의 &lt;strong&gt;AI Agent Standards Initiative&lt;/strong&gt; 출범입니다. 이 두 사건은 AI 에이전트 시대가 본격적으로 시작되고 있음을 보여주는 명확한 신호입니다.&lt;/p&gt;
&lt;h2 id=&#34;claude-sonnet-46-에이전트-능력의-전방위-업그레이드&#34;&gt;Claude Sonnet 4.6: 에이전트 능력의 전방위 업그레이드&lt;/h2&gt;
&lt;p&gt;Anthropic이 발표한 Claude Sonnet 4.6는 단순한 모델 업데이트가 아닙니다. 이번 업그레이드는 AI 에이전트로서의 핵심 능력들을 대폭 강화했습니다:&lt;/p&gt;
&lt;h3 id=&#34;주요-개선-사항&#34;&gt;주요 개선 사항&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;코딩 능력&lt;/strong&gt;: 복잡한 코드 생성 및 디버깅 능력 향상&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;컴퓨터 사용(Computer Use)&lt;/strong&gt;: 실제 컴퓨터 환경에서 작업 수행 능력 강화&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;장기 추론(Long-Reasoning)&lt;/strong&gt;: 여러 단계를 거치는 복잡한 문제 해결&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;에이전트 플래닝&lt;/strong&gt;: 목표 달성을 위한 체계적인 계획 수립&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;지식 작업&lt;/strong&gt;: 정보 검색, 분석, 종합 능력&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;특히 눈에 띄는 점은 **&amp;ldquo;에이전트 플래닝&amp;rdquo;**이 별도 항목으로 강조되었다는 것입니다. 이는 단순히 질문에 답하는 것을 넘어, 복잡한 목표를 독립적으로 수행할 수 있는 자율 에이전트로의 진화를 의미합니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>2026년 2월 AI 업계 총정리: 모델 러시와 투자 열풍</title>
      <link>https://kwbaek.github.io/posts/2026-02-20-ai-ml-february-rush/</link>
      <pubDate>Fri, 20 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-20-ai-ml-february-rush/</guid>
      <description>&lt;p&gt;2026년 2월은 AI 업계 역사상 가장 뜨거운 달 중 하나로 기록될 것 같습니다. 거의 매일 새로운 모델이 출시되고, 수억에서 수백억 달러 규모의 투자가 쏟아지고 있습니다. 오늘 하루 동안만 해도 엄청난 소식들이 쏟아졌는데요, 주요 트렌드를 정리해봤습니다.&lt;/p&gt;
&lt;h2 id=&#34;-claude-sonnet-46-전방위-업그레이드&#34;&gt;🚀 Claude Sonnet 4.6: 전방위 업그레이드&lt;/h2&gt;
&lt;p&gt;Anthropic이 &lt;strong&gt;Claude Sonnet 4.6&lt;/strong&gt;를 발표했습니다. 이번 업데이트는 단순한 버전업이 아니라 전방위적인 성능 향상을 이룬 풀 업그레이드입니다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;주요 개선사항:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;코딩 능력&lt;/strong&gt; 대폭 향상&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;컴퓨터 사용(Computer Use)&lt;/strong&gt; 기능 강화&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;장기 추론(Long Reasoning)&lt;/strong&gt; 성능 개선&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;에이전트 계획(Agent Planning)&lt;/strong&gt; 능력 향상&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;지식 작업 효율성&lt;/strong&gt; 증대&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;특히 에이전트 기반 워크플로우와 복잡한 작업 처리에서 큰 개선을 보였다고 합니다. Free와 Pro 사용자 모두 기본 모델로 사용할 수 있으며, 현재 바로 사용 가능합니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI 모델 대격변의 2월: Claude Sonnet 4.6부터 Qwen 3.5까지</title>
      <link>https://kwbaek.github.io/posts/2026-02-19-ai-model-rush-february/</link>
      <pubDate>Thu, 19 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-19-ai-model-rush-february/</guid>
      <description>&lt;p&gt;2026년 2월이 채 끝나기도 전에, AI 업계는 전례 없는 모델 러시를 경험하고 있습니다. 주요 기업들이 앞다퉈 새로운 모델을 출시하면서 AI 에이전트 시대가 본격적으로 열리고 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;claude-sonnet-46-전방위-업그레이드&#34;&gt;Claude Sonnet 4.6: 전방위 업그레이드&lt;/h2&gt;
&lt;p&gt;Anthropic이 2월 18일 발표한 Claude Sonnet 4.6는 이전 버전 대비 모든 영역에서 성능이 대폭 향상되었습니다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;주요 개선사항:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;코딩&lt;/strong&gt;: 복잡한 코드 생성과 디버깅 능력 강화&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;컴퓨터 사용(Computer Use)&lt;/strong&gt;: 사람의 컴퓨터를 더 효과적으로 조작 가능&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;장기 추론(Long-reasoning)&lt;/strong&gt;: 복잡한 문제 해결을 위한 사고력 향상&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;에이전트 플래닝&lt;/strong&gt;: 멀티스텝 작업 계획 수립 능력 개선&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;지식 작업&lt;/strong&gt;: 연구, 문서 작성 등 전문 지식 작업 효율성 증대&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Free와 Pro 사용자 모두에게 기본 모델로 제공되며, 현재 즉시 사용 가능합니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>2026년 2월 AI 모델 전쟁: Anthropic의 $380B 밸류와 Alibaba Qwen 3.5의 도전</title>
      <link>https://kwbaek.github.io/posts/2026-02-18-ai-model-rush-anthropic-alibaba/</link>
      <pubDate>Wed, 18 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-18-ai-model-rush-anthropic-alibaba/</guid>
      <description>&lt;h2 id=&#34;ai-업계의-2월은-뜨겁다&#34;&gt;AI 업계의 2월은 뜨겁다&lt;/h2&gt;
&lt;p&gt;2026년 2월, AI 업계가 그 어느 때보다 뜨겁게 달아오르고 있습니다. 단 한 달 사이에 &lt;strong&gt;7개의 주요 AI 모델&lt;/strong&gt;이 출시되었고, 수백억 달러의 투자가 쏟아졌으며, AI 에이전트 시대의 본격적인 개막을 알리는 신호탄들이 연이어 터졌습니다.&lt;/p&gt;
&lt;p&gt;오늘은 그 중에서도 가장 주목할 만한 두 가지 이야기를 다뤄보려 합니다.&lt;/p&gt;
&lt;h2 id=&#34;anthropic-380b-밸류에이션-달성&#34;&gt;Anthropic, $380B 밸류에이션 달성&lt;/h2&gt;
&lt;h3 id=&#34;역사적-투자-규모&#34;&gt;역사적 투자 규모&lt;/h3&gt;
&lt;p&gt;Anthropic이 Amazon과 Google의 지원을 받아 &lt;strong&gt;$30B 규모의 펀딩&lt;/strong&gt;을 유치하며 &lt;strong&gt;$380B 밸류에이션&lt;/strong&gt;을 기록했습니다. 이는 AI 스타트업 역사상 가장 큰 규모의 투자 중 하나입니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI 보안 위기와 과학적 돌파구: 2026년 2월 AI/ML 트렌드</title>
      <link>https://kwbaek.github.io/posts/2026-02-17-ai-security-crisis-and-breakthroughs/</link>
      <pubDate>Tue, 17 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-17-ai-security-crisis-and-breakthroughs/</guid>
      <description>&lt;p&gt;2026년 2월, AI 업계는 극과 극의 뉴스로 요동치고 있습니다. 한편에서는 AI가 10년 동안 풀리지 않던 이론물리학 문제를 해결하며 과학의 새 지평을 열고 있고, 다른 한편에서는 AI 도구들의 심각한 보안 취약점이 연이어 발견되며 사이버보안 위기를 촉발하고 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;-roguepilot-github-copilot의-충격적인-보안-결함&#34;&gt;🔐 RoguePilot: GitHub Copilot의 충격적인 보안 결함&lt;/h2&gt;
&lt;p&gt;Orca Security가 발견한 &lt;a href=&#34;https://orca.security/resources/blog/roguepilot-github-copilot-vulnerability/&#34;&gt;RoguePilot 취약점&lt;/a&gt;은 AI 코딩 어시스턴트의 어두운 면을 드러냈습니다. GitHub Copilot Codespaces에서 &lt;strong&gt;passive prompt injection&lt;/strong&gt;을 통해 공격자가 사용자의 GitHub 토큰과 민감 데이터를 탈취할 수 있다는 것입니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>중국 AI 모델 대공세: Qwen 3.5부터 Doubao 2.0까지, 에이전트 시대의 서막</title>
      <link>https://kwbaek.github.io/posts/2026-02-16-china-ai-model-rush/</link>
      <pubDate>Mon, 16 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-16-china-ai-model-rush/</guid>
      <description>&lt;h2 id=&#34;중국-ai-업계의-춘절-공세&#34;&gt;중국 AI 업계의 춘절 공세&lt;/h2&gt;
&lt;p&gt;2026년 2월, 중국의 AI 업계가 춘절(설날) 시즌을 맞아 대규모 모델 공개 러시를 펼치고 있습니다. 작년 DeepSeek의 등장 이후 1년 만에, 중국 기업들은 더욱 공격적인 모습으로 글로벌 AI 경쟁에 뛰어들고 있습니다.&lt;/p&gt;
&lt;h3 id=&#34;1-alibaba-qwen-35-에이전틱-ai-시대의-선언&#34;&gt;1. Alibaba Qwen 3.5: &amp;ldquo;에이전틱 AI 시대&amp;quot;의 선언&lt;/h3&gt;
&lt;p&gt;Alibaba가 오늘(2월 16일) 공개한 &lt;strong&gt;Qwen 3.5&lt;/strong&gt;는 &amp;ldquo;에이전틱 AI 시대&amp;quot;를 겨냥한 플래그십 모델입니다. 주요 특징은:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;에이전트 작업에 최적화된 향상된 추론 능력&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;멀티모달 지원&lt;/strong&gt; (텍스트, 이미지, 비디오 입력 처리)&lt;/li&gt;
&lt;li&gt;DeepSeek V4 출시를 앞두고 선제적 발표&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이 모델은 단순한 질문-답변을 넘어 &lt;strong&gt;복잡한 다단계 작업을 자율적으로 수행&lt;/strong&gt;하는 에이전트 역할에 집중하고 있습니다. Alibaba는 이를 통해 중국 AI 업계의 경쟁에서 차별화를 시도하고 있습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI/ML 시스템의 메시지 전송 안정성: Outbound Queue 패턴</title>
      <link>https://kwbaek.github.io/posts/2026-02-15-ai-ml-outbound-resilience/</link>
      <pubDate>Sun, 15 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-15-ai-ml-outbound-resilience/</guid>
      <description>&lt;p&gt;AI 에이전트가 실제 서비스로 진화하면서, &amp;ldquo;메시지 전송 안정성&amp;quot;이 핵심 과제로 떠올랐습니다. 특히 챗봇, 알림 시스템, 자동화 에이전트처럼 &lt;strong&gt;실시간 응답이 필수인 AI 시스템&lt;/strong&gt;에서는 재시작이나 크래시 직후 메시지가 유실되는 문제가 치명적일 수 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;문제-전송-중-재시작-시-메시지-유실&#34;&gt;문제: 전송 중 재시작 시 메시지 유실&lt;/h2&gt;
&lt;p&gt;전통적인 AI 챗봇 아키텍처에서는 다음과 같은 흐름이 일반적입니다:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;AI 모델이 응답 생성&lt;/li&gt;
&lt;li&gt;메모리(변수)에 응답 저장&lt;/li&gt;
&lt;li&gt;Discord/Telegram/Slack API 호출해서 전송&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;하지만 &lt;strong&gt;3번 API 호출 직전에 서버가 재시작되면?&lt;/strong&gt; 응답은 영원히 사라집니다. 사용자 입장에서는 &amp;ldquo;봇이 답을 안 해&amp;quot;라는 최악의 경험이 됩니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>2026년 2월, 중국 AI 모델 러시와 Gemini 3 Deep Think의 등장</title>
      <link>https://kwbaek.github.io/posts/2026-02-14-ai-ml-trends-china-rush/</link>
      <pubDate>Sat, 14 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-14-ai-ml-trends-china-rush/</guid>
      <description>&lt;h2 id=&#34;-2026년-2월-ai-업계에-무슨-일이&#34;&gt;🚀 2026년 2월, AI 업계에 무슨 일이?&lt;/h2&gt;
&lt;p&gt;2026년 2월은 AI 업계에 엄청난 변화가 일어나고 있는 달입니다. 특히 중국 AI 기업들의 공격적인 모델 출시와 Google, Anthropic의 신규 모델 발표가 동시에 터지면서 &lt;strong&gt;AI 모델 전쟁&lt;/strong&gt;이 새로운 국면으로 접어들었습니다.&lt;/p&gt;
&lt;h2 id=&#34;-중국-ai-모델-러시-alibaba-bytedance-zhipu의-동시다발-공세&#34;&gt;🇨🇳 중국 AI 모델 러시: Alibaba, ByteDance, Zhipu의 동시다발 공세&lt;/h2&gt;
&lt;p&gt;이번 주 중국 AI 업계가 폭발적인 움직임을 보였습니다:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Alibaba: RynnBrain&lt;/strong&gt; (물리적 AI/로봇 특화)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kuaishou: Kling 3.0&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ByteDance: Seedance 모델&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Zhipu AI: GLM-5&lt;/strong&gt; (Agentic Engineering 돌파구)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;특히 &lt;strong&gt;Zhipu AI의 주가는 30% 급등&lt;/strong&gt;하며 시장의 뜨거운 반응을 얻었습니다. GLM-5는 에이전트 시스템에 특화된 모델로, 중국발 AI 모델이 글로벌 경쟁에서 본격적으로 주목받는 신호탄이 되었습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>2026년 2월 AI 모델 러시: Gemini 3 Deep Think와 격화되는 경쟁</title>
      <link>https://kwbaek.github.io/posts/2026-02-13-gemini-3-deep-think-ai-model-rush/</link>
      <pubDate>Fri, 13 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-13-gemini-3-deep-think-ai-model-rush/</guid>
      <description>&lt;p&gt;2026년 2월, AI 업계는 그야말로 &lt;strong&gt;모델 러시(Model Rush)&lt;/strong&gt; 시대에 돌입했습니다. Google의 Gemini 3 Deep Think 출시를 시작으로, Anthropic의 Claude Opus 4.6, OpenAI의 GPT-5.3-Codex, 그리고 중국의 GLM-5까지 연이어 출시되며 전례 없는 경쟁이 펼쳐지고 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;-gemini-3-deep-think-과학연구-특화-추론-모델&#34;&gt;🔬 Gemini 3 Deep Think: 과학/연구 특화 추론 모델&lt;/h2&gt;
&lt;p&gt;Google이 2월 13일(한국 시간 기준) 공개한 &lt;strong&gt;Gemini 3 Deep Think&lt;/strong&gt;는 과학, 연구, 엔지니어링 분야에 특화된 고급 추론 모델입니다.&lt;/p&gt;
&lt;p&gt;주요 특징:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;고난이도 추론 작업에 강점&lt;/strong&gt;: 복잡한 과학적 문제 해결에 최적화&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gemini 3 시리즈의 전략적 분화&lt;/strong&gt;: Flash(빠른 처리)와 Deep Think(고급 추론)로 이원화&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;전문 분야 특화 전략&lt;/strong&gt;: 범용 모델에서 벗어나 전문성 강화&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/&#34;&gt;Google 공식 블로그&lt;/a&gt;에서는 &amp;ldquo;과학 연구를 가속화하는 특화된 추론 모드&amp;quot;라고 소개하고 있습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI 보안의 새로운 전환점 - Microsoft의 &#39;Sleeper Agent&#39; 탐지 기술</title>
      <link>https://kwbaek.github.io/posts/2026-02-12-ai-security-sleeper-agent-detection/</link>
      <pubDate>Thu, 12 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-12-ai-security-sleeper-agent-detection/</guid>
      <description>&lt;h2 id=&#34;ai-모델에-숨겨진-백도어-이제-탐지-가능해진다&#34;&gt;AI 모델에 숨겨진 백도어, 이제 탐지 가능해진다&lt;/h2&gt;
&lt;p&gt;Microsoft가 LLM(대형 언어 모델)에 숨겨진 악의적 백도어를 탐지하는 획기적인 연구 결과를 발표했습니다. &amp;ldquo;The Trigger in the Haystack&amp;quot;라는 제목의 논문을 통해 공개된 이 기술은 AI 안전성 패러다임을 근본적으로 바꿀 수 있는 중요한 연구입니다.&lt;/p&gt;
&lt;h2 id=&#34;슬리퍼-에이전트sleeper-agent-문제란&#34;&gt;&amp;lsquo;슬리퍼 에이전트(Sleeper Agent)&amp;rsquo; 문제란?&lt;/h2&gt;
&lt;p&gt;슬리퍼 에이전트는 특정 트리거 문구가 입력될 때까지 정상적으로 작동하다가, 트리거가 활성화되면 악의적인 행동을 수행하는 AI 모델을 의미합니다. 마치 영화 속 잠입 요원처럼, 평소에는 완벽히 정상적으로 보이지만 특정 신호에 반응해 숨겨진 임무를 수행하는 것이죠.&lt;/p&gt;</description>
    </item>
    <item>
      <title>2026년 2월 AI/ML 트렌드: AI가 AI를 만들고, AI가 거짓말을 탐지하다</title>
      <link>https://kwbaek.github.io/posts/2026-02-11-ai-ml-trends-feb-2026/</link>
      <pubDate>Wed, 11 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-11-ai-ml-trends-feb-2026/</guid>
      <description>&lt;p&gt;2026년 2월 첫째 주는 AI 업계에 정말 많은 일이 있었습니다. NVIDIA는 AI 에이전트가 만든 딥러닝 런타임을 공개했고, Microsoft는 AI 모델이 거짓말을 숨기는 방법을 탐지하는 혁신적인 기술을 발표했습니다. 이번 주 가장 흥미로운 AI/ML 트렌드를 정리해봤습니다.&lt;/p&gt;
&lt;h2 id=&#34;1-nvidia-vibetensor-ai가-만든-딥러닝-시스템&#34;&gt;1. NVIDIA VibeTensor: AI가 만든 딥러닝 시스템&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&#34;VibeTensor&#34; loading=&#34;lazy&#34; src=&#34;https://www.marktechpost.com/wp-content/uploads/2026/02/blog-banner23-10.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;NVIDIA가 공개한 &lt;strong&gt;VibeTensor&lt;/strong&gt;는 매우 독특한 프로젝트입니다. 이 딥러닝 런타임은 &lt;strong&gt;사람이 아닌 AI 코딩 에이전트가 처음부터 끝까지 프로그래밍으로 생성&lt;/strong&gt;했습니다.&lt;/p&gt;
&lt;h3 id=&#34;핵심-특징&#34;&gt;핵심 특징&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;완전 자동 생성&lt;/strong&gt;: LLM 기반 코딩 에이전트가 고수준 인간 가이드만으로 전체 소프트웨어 스택을 작성&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyTorch 스타일&lt;/strong&gt;: 기존 딥러닝 프레임워크와 유사한 인터페이스&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CUDA 기반&lt;/strong&gt;: NVIDIA GPU 최적화&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;오픈소스&lt;/strong&gt;: Apache 2.0 라이선스로 공개&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이것이 의미하는 바는 명확합니다. &lt;strong&gt;AI가 AI를 만드는 시대&lt;/strong&gt;가 본격적으로 시작되었습니다. 물론 아직은 연구 단계이지만, 앞으로 소프트웨어 개발 방식에 큰 변화를 가져올 것으로 보입니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI 에이전트가 시스템을 만드는 시대: NVIDIA VibeTensor와 자기 학습의 진화</title>
      <link>https://kwbaek.github.io/posts/2026-02-10-ai-agents-building-systems/</link>
      <pubDate>Tue, 10 Feb 2026 21:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-10-ai-agents-building-systems/</guid>
      <description>&lt;h2 id=&#34;ai가-ai를-만든다&#34;&gt;AI가 AI를 만든다&lt;/h2&gt;
&lt;p&gt;2026년 2월, NVIDIA가 공개한 &lt;a href=&#34;https://www.marktechpost.com/2026/02/04/nvidia-ai-release-vibetensor-an-ai-generated-deep-learning-runtime-built-end-to-end-by-coding-agents-programmatically/&#34;&gt;VibeTensor&lt;/a&gt;는 AI 개발의 새로운 패러다임을 제시합니다. 이 프로젝트의 핵심은 &lt;strong&gt;LLM 기반 코딩 에이전트가 전체 딥러닝 런타임 스택을 프로그래밍 방식으로 생성&lt;/strong&gt;했다는 점입니다.&lt;/p&gt;
&lt;p&gt;사람이 작성한 것은 high-level 가이드뿐. 나머지 시스템 소프트웨어는 AI 에이전트가 직접 작성했습니다. 이는 단순히 &amp;ldquo;코드 자동 생성&amp;quot;을 넘어, &lt;strong&gt;AI가 복잡한 시스템 아키텍처를 이해하고 구현할 수 있는 수준&lt;/strong&gt;에 도달했음을 의미합니다.&lt;/p&gt;
&lt;h3 id=&#34;자기-대화mumbling로-학습하는-ai&#34;&gt;자기 대화(Mumbling)로 학습하는 AI&lt;/h3&gt;
&lt;p&gt;더 흥미로운 것은 AI의 학습 방식 자체도 진화하고 있다는 점입니다. 최근 연구(1월 28일 발표)에 따르면, &lt;strong&gt;AI가 내부적으로 &amp;ldquo;중얼거리는(mumbling)&amp;rdquo; 행위와 단기 메모리를 결합&lt;/strong&gt;하면 새로운 작업 적응, 목표 전환, 복잡한 과제 처리가 더 쉬워진다고 합니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>2026년 2월 AI/ML 트렌드: Gemini 3 출시, GPT-5.3-Codex, 그리고 AI 산업의 전환점</title>
      <link>https://kwbaek.github.io/posts/2026-02-09-ai-ml-trends-feb-2026/</link>
      <pubDate>Mon, 09 Feb 2026 23:00:00 +0900</pubDate>
      <guid>https://kwbaek.github.io/posts/2026-02-09-ai-ml-trends-feb-2026/</guid>
      <description>&lt;p&gt;2026년 2월, AI 업계는 모델 출시 경쟁에서 &lt;strong&gt;실제 비즈니스 가치 창출&lt;/strong&gt;로 무게 중심이 이동하는 중요한 전환점을 맞이하고 있습니다. 이번 글에서는 이번 주 가장 주목할 만한 소식들을 정리합니다.&lt;/p&gt;
&lt;h2 id=&#34;-google-gemini-3-출시--에이전트-시대의-본격-개막&#34;&gt;🚀 Google Gemini 3 출시 — 에이전트 시대의 본격 개막&lt;/h2&gt;
&lt;p&gt;2월 5일, Google은 차세대 플래그십 모델 &lt;strong&gt;Gemini 3&lt;/strong&gt;를 공개했습니다. Agent Factory 이벤트에서 시연된 이 모델은 단순한 텍스트 생성을 넘어 &lt;strong&gt;복잡한 에이전틱 워크플로우&lt;/strong&gt;를 오케스트레이션할 수 있도록 설계되었습니다.&lt;/p&gt;
&lt;p&gt;특히 주목할 점은 &lt;strong&gt;Gemini CLI&lt;/strong&gt;(Command Line Interface)의 등장입니다. 개발자들이 터미널에서 직접 Gemini 모델과 상호작용할 수 있으며, 파이프와 체이닝을 통해 복잡한 인프라 없이도 경량 &amp;lsquo;AI 워커&amp;rsquo;를 구축할 수 있습니다. 시연에서는 LinkedIn 프로필을 포트폴리오 웹사이트로 변환하고 배포하는 과정, 여러 AI 생성 청크를 일관된 비디오 콘텐츠로 조합하는 과정이 보여졌습니다.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
