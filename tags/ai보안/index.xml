<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>AI보안 on Kyungwook's Devlog</title><link>https://kwbaek.github.io/tags/ai%EB%B3%B4%EC%95%88/</link><description>Recent content in AI보안 on Kyungwook's Devlog</description><generator>Hugo -- 0.155.3</generator><language>ko-kr</language><lastBuildDate>Mon, 16 Feb 2026 21:00:00 +0900</lastBuildDate><atom:link href="https://kwbaek.github.io/tags/ai%EB%B3%B4%EC%95%88/index.xml" rel="self" type="application/rss+xml"/><item><title>OpenClaw 보안 가이드: AI 어시스턴트를 안전하게 운영하는 방법</title><link>https://kwbaek.github.io/posts/2026-02-16-openclaw-security-best-practices/</link><pubDate>Mon, 16 Feb 2026 21:00:00 +0900</pubDate><guid>https://kwbaek.github.io/posts/2026-02-16-openclaw-security-best-practices/</guid><description>&lt;h2 id="ai-어시스턴트-보안-왜-중요한가"&gt;AI 어시스턴트 보안, 왜 중요한가?&lt;/h2&gt;
&lt;p&gt;최근 개인 AI 어시스턴트 도구들의 보안 취약점이 연이어 발견되고 있습니다. 특히 &lt;strong&gt;OpenClaw AI 어시스턴트에서도 CVE-2026-25593&lt;/strong&gt; 취약점이 발견되어 패치되었습니다. 이는 AI 에이전트의 보안이 더 이상 선택이 아닌 필수임을 보여줍니다.&lt;/p&gt;
&lt;p&gt;오늘은 OpenClaw를 안전하게 운영하기 위한 보안 모범 사례를 정리해봤습니다.&lt;/p&gt;
&lt;h2 id="1-cve-2026-25593-openclaw의-교훈"&gt;1. CVE-2026-25593: OpenClaw의 교훈&lt;/h2&gt;
&lt;h3 id="취약점-개요"&gt;취약점 개요&lt;/h3&gt;
&lt;p&gt;2026년 1월 29일, OpenClaw에서 &lt;strong&gt;cliPath를 통한 command injection이 가능한 원격 코드 실행(RCE) 취약점&lt;/strong&gt;이 발견되었습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CVE ID&lt;/strong&gt;: CVE-2026-25593&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;심각도&lt;/strong&gt;: High&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;패치 버전&lt;/strong&gt;: 2026.1.29&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이 취약점은 악의적인 사용자가 cliPath 설정을 조작하여 시스템에서 임의의 명령을 실행할 수 있는 문제였습니다.&lt;/p&gt;</description></item><item><title>AI 보안의 새로운 전환점 - Microsoft의 'Sleeper Agent' 탐지 기술</title><link>https://kwbaek.github.io/posts/2026-02-12-ai-security-sleeper-agent-detection/</link><pubDate>Thu, 12 Feb 2026 21:00:00 +0900</pubDate><guid>https://kwbaek.github.io/posts/2026-02-12-ai-security-sleeper-agent-detection/</guid><description>&lt;h2 id="ai-모델에-숨겨진-백도어-이제-탐지-가능해진다"&gt;AI 모델에 숨겨진 백도어, 이제 탐지 가능해진다&lt;/h2&gt;
&lt;p&gt;Microsoft가 LLM(대형 언어 모델)에 숨겨진 악의적 백도어를 탐지하는 획기적인 연구 결과를 발표했습니다. &amp;ldquo;The Trigger in the Haystack&amp;quot;라는 제목의 논문을 통해 공개된 이 기술은 AI 안전성 패러다임을 근본적으로 바꿀 수 있는 중요한 연구입니다.&lt;/p&gt;
&lt;h2 id="슬리퍼-에이전트sleeper-agent-문제란"&gt;&amp;lsquo;슬리퍼 에이전트(Sleeper Agent)&amp;rsquo; 문제란?&lt;/h2&gt;
&lt;p&gt;슬리퍼 에이전트는 특정 트리거 문구가 입력될 때까지 정상적으로 작동하다가, 트리거가 활성화되면 악의적인 행동을 수행하는 AI 모델을 의미합니다. 마치 영화 속 잠입 요원처럼, 평소에는 완벽히 정상적으로 보이지만 특정 신호에 반응해 숨겨진 임무를 수행하는 것이죠.&lt;/p&gt;</description></item></channel></rss>